{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c226f4",
   "metadata": {},
   "source": [
    "# 1. Create dummy train and test data as np.arrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53953db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55be3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[-0.86143957,0.51365619]\n",
    "                   ,[ 0.15802293, 0.75413978]\n",
    "                   ,[ 0.10045332,-1.02042385]\n",
    "                   ,[ 0.21542833, 0.81745144]\n",
    "                   ,[-0.33609156, 0.83596599]\n",
    "                   ,[ 0.67947953,-0.23228435]\n",
    "                   ,[ 0.72633661,-0.68139863]\n",
    "                   ,[ 0.64147019,-0.78286524]\n",
    "                   ,[ 0.87929062, 0.49881147]\n",
    "                   ,[ 0.11631592, 0.77449553]])\n",
    "\n",
    "y_train = np.array([0, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
    "X_test = np.array([[-0.78586889,  0.59082396],\n",
    "                [-0.70465859,  0.34926669],\n",
    "                [-0.70729354, -0.48752429],\n",
    "                [ 0.11865543, -0.86599624],\n",
    "                [-0.23169779, -0.91255477],\n",
    "                [ 0.8423562 ,  0.16031322],\n",
    "                [-0.14796425,  1.01458079],\n",
    "                [-0.04146067,  0.9391543 ],\n",
    "                [ 0.74951054,  0.32433079],\n",
    "                [-0.70183734,  0.6173987 ]])\n",
    "y_test = np.array([0, 1, 1, 1, 0, 1, 0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842345b",
   "metadata": {},
   "source": [
    "# 2. Convert the train and test data from np.arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55daaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Convert data to torch tensors\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "# Instantiate training and test data\n",
    "train_data = Data(X_train, y_train)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = Data(X_test, y_test)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53813d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "X shape: torch.Size([5, 2])\n",
      "y shape: torch.Size([5])\n",
      "Batch: 2\n",
      "X shape: torch.Size([5, 2])\n",
      "y shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# Check if it's working using the train data: Expect 2 batches since batch size is 5\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(f\"Batch: {batch+1}\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e1a99",
   "metadata": {},
   "source": [
    "# 3. Create a simple two-layer neural network that uses the rectified linear unit(ReLU) activation function (torch.nn.functional.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e758014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        nn.init.kaiming_uniform_(self.layer_1.weight, nonlinearity=\"relu\")\n",
    "        self.layer_2 = nn.Linear(hidden_dim, output_dim)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer_1(x))\n",
    "        x = torch.nn.functional.sigmoid(self.layer_2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5902c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer_1): Linear(in_features=2, out_features=10, bias=True)\n",
       "  (layer_2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35048fb5",
   "metadata": {},
   "source": [
    "# 4. Define train function with binary crossentropy loss and stochastic gradient descent optimizer with a learning rate of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37eb7496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40531d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.1\n",
    "loss_values = []\n",
    "device = 'cuda' if torch.distributed.is_nccl_available() else 'cpu'\n",
    "back_end = 'nccl' if device=='cuda' else 'gloo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d698e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distribute():\n",
    "    #### These imports HAVE TO be included INSIDE of this train function in order to be installed on each worker. ####\n",
    "    import torch.distributed as dist\n",
    "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "    from torch.utils.data.distributed import DistributedSampler\n",
    "    \n",
    "    print(\"Running distributed training\")\n",
    "\n",
    "    os.environ['MASTER_ADDR'] = '192.168.1.70'\n",
    "    os.environ['MASTER_PORT'] = '4040'\n",
    "    dist.init_process_group(backend=back_end, init_method='env://', rank = 1, world_size = 1)\n",
    "    \n",
    "    #### Added Distributed Train Dataloader ####\n",
    "    train_data = Data(X_train, y_train)\n",
    "    train_sampler = DistributedSampler(dataset=train_data)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler) \n",
    "    \n",
    "    #### Added Distributed Model ####\n",
    "    model = NeuralNetwork(input_dim, hidden_dim, output_dim).to(device)\n",
    "    ddp_model = DDP(model) # device_ids=[local_rank], output_device=local_rank)\n",
    "    \n",
    "    #### Train Model ####\n",
    "    learning_rate = 0.1\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(ddp_model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        ddp_model.train()\n",
    "        for batch_idx, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            pred = ddp_model(X)\n",
    "            loss = loss_fn(pred, y.unsqueeze(-1))\n",
    "            loss_values.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(X), len(train_dataloader) * len(X),\n",
    "                100. * batch_idx / len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02337dcb",
   "metadata": {},
   "source": [
    "# 5. Test without TorchDistributor\n",
    "### The following validates the training loop by running training on a single CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02a3ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running distributed training\n"
     ]
    }
   ],
   "source": [
    "train_distribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ca383",
   "metadata": {},
   "source": [
    "# 6. Single node multi-CPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e9fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"test\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d4fb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "spark.conf.set(\"spark.sql.files.ignoreCorruptFiles\", True)\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f21948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchDistributor(num_processes=1, local_mode=False, use_gpu=True).run(train_distribute)\n",
    "df = spark.read.option(\"header\",\"true\") \\\n",
    ".format(\"csv\") \\\n",
    ".load(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923077a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal.length|sepal.width|petal.length|petal.width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|         .2| Setosa|\n",
      "|         4.9|          3|         1.4|         .2| Setosa|\n",
      "|         4.7|        3.2|         1.3|         .2| Setosa|\n",
      "|         4.6|        3.1|         1.5|         .2| Setosa|\n",
      "|           5|        3.6|         1.4|         .2| Setosa|\n",
      "|         5.4|        3.9|         1.7|         .4| Setosa|\n",
      "|         4.6|        3.4|         1.4|         .3| Setosa|\n",
      "|           5|        3.4|         1.5|         .2| Setosa|\n",
      "|         4.4|        2.9|         1.4|         .2| Setosa|\n",
      "|         4.9|        3.1|         1.5|         .1| Setosa|\n",
      "|         5.4|        3.7|         1.5|         .2| Setosa|\n",
      "|         4.8|        3.4|         1.6|         .2| Setosa|\n",
      "|         4.8|          3|         1.4|         .1| Setosa|\n",
      "|         4.3|          3|         1.1|         .1| Setosa|\n",
      "|         5.8|          4|         1.2|         .2| Setosa|\n",
      "|         5.7|        4.4|         1.5|         .4| Setosa|\n",
      "|         5.4|        3.9|         1.3|         .4| Setosa|\n",
      "|         5.1|        3.5|         1.4|         .3| Setosa|\n",
      "|         5.7|        3.8|         1.7|         .3| Setosa|\n",
      "|         5.1|        3.8|         1.5|         .3| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22956f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
